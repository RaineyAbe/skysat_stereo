{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEM post-processing: vertical adjustment with GCPs and error assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xdem\n",
    "import geoutils as gu\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "# Define paths in directory\n",
    "data_dir = f\"/Volumes/LaCie/raineyaberle/Research/PhD/Skysat-Stereo/study-sites/\"\n",
    "site_name = \"JacksonPeak\"\n",
    "date = \"20240420\"\n",
    "dem_fn = os.path.join(data_dir, site_name, date, f\"ba+DEMuncertainty1mAll_{site_name}_{date}_DEM.tif\")\n",
    "# refdem_fn = os.path.join(data_dir, site_name, 'refdem', f'{site_name}_REFDEM_WGS84.tif')\n",
    "refdem_fn = os.path.join(data_dir, site_name, \"refdem\", \"USGS_LPC_ID_FEMAHQ_2018_D18_merged_filtered.tif\")\n",
    "ss_mask_fn = os.path.join(data_dir, site_name, date, \"stable_surfaces\", \"stable_surfaces_mask.tif\")\n",
    "snow_mask_fn = os.path.join(data_dir, site_name, date, \"stable_surfaces\", \"snow_mask.tif\")\n",
    "# gcp_fn = \"/Volumes/LaCie/raineyaberle/Research/PhD/SkySat-Stereo/ITD_Functional_Class/ITD_HWY_21.shp\"\n",
    "# gcp_elev = 0\n",
    "gcp_fn = os.path.join(data_dir, site_name, \"snotel\", \"JacksonPeak_snotel_site_info.gpkg\")\n",
    "gcp_elev = 1.45\n",
    "out_dir = os.path.join(data_dir, site_name, date, \"post_process\")\n",
    "\n",
    "# Check that input files exist\n",
    "for file, name in [[dem_fn, 'DEM'], [refdem_fn, 'Reference DEM'], \n",
    "                   [ss_mask_fn, 'Stable surfaces'], [snow_mask_fn, 'Snow mask'], [gcp_fn, \"GCP\"]]:\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"{name} not found, please fix before continuing\")\n",
    "\n",
    "# Make output directory\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_zshift_fn = os.path.join(out_dir, os.path.splitext(os.path.basename(dem_fn))[0] + '_GCPshift.tif')\n",
    "if not os.path.exists(dem_zshift_fn):\n",
    "    # Load input files\n",
    "    dem = xdem.DEM(dem_fn)\n",
    "    refdem = xdem.DEM(refdem_fn).reproject(dem)\n",
    "    gcp = gu.Vector(gcp_fn).reproject(dem)\n",
    "    gcp = gcp.create_mask(dem)\n",
    "    ss_mask = gu.Raster(ss_mask_fn).reproject(dem)\n",
    "    ss_mask = (ss_mask == 1)\n",
    "    \n",
    "    # Calculate dDEM\n",
    "    ddem = dem - refdem\n",
    "    \n",
    "    dem.set_nodata(np.nan, update_array=True)\n",
    "    ddem.set_nodata(np.nan, update_array=True)\n",
    "    \n",
    "    # Sample dDEM at GCP points\n",
    "    ddem_gcp = ddem[gcp]\n",
    "    ddem_gcp_median = np.nanmedian(ddem_gcp.data)\n",
    "    zshift = -ddem_gcp_median + gcp_elev\n",
    "    print(f\"Vertical adjustment from GCP = {np.round(float(zshift), 2)} m\")\n",
    "    \n",
    "    # Apply vertical adjustment to DEM\n",
    "    dem_zshift = dem + zshift\n",
    "    ddem_zshift = ddem + zshift\n",
    "    # Save to file\n",
    "    dem_zshift.save(dem_zshift_fn)\n",
    "    print('Shifted DEM saved to file:', dem_zshift_fn)\n",
    "    \n",
    "    ddem_zshift.plot(cmap='coolwarm_r', vmin=-5, vmax=5)\n",
    "    plt.show()\n",
    "    \n",
    "    # Make serializable dictionary of results\n",
    "    zshift_dict = {'original_GCP_dDEM_values_m': json.dumps([float(x) for x in ddem_gcp.data]),\n",
    "                   'GCP_dDEM_median_m': json.dumps(float(ddem_gcp_median)),\n",
    "                   'DEM_vertical_shift_m': json.dumps(float(zshift))}  \n",
    "\n",
    "    # Save to file\n",
    "    zshift_dict_fn = os.path.splitext(dem_zshift_fn)[0] + '.json'\n",
    "    with open(zshift_dict_fn, \"w\") as f:\n",
    "        json.dump(zshift_dict, f)\n",
    "    print('Vertical shift dictionary saved to file:', zshift_dict_fn)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dDEM stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_fig_fn = os.path.splitext(dem_zshift_fn)[0] + '_dDEM_stats.png'\n",
    "if not os.path.exists(stats_fig_fn):\n",
    "    # Load shifted DEM and reference DEM\n",
    "    dem = xdem.DEM(dem_zshift_fn)\n",
    "    refdem = xdem.DEM(refdem_fn).reproject(dem)\n",
    "    ddem = dem - refdem\n",
    "    \n",
    "    # Mask unstable surfaces\n",
    "    ss_mask = gu.Raster(ss_mask_fn).reproject(dem)\n",
    "    ss_mask = (ss_mask==1)\n",
    "    ddem_ss = ddem[ss_mask]\n",
    "    \n",
    "    # Calculate median, NMAD, and quantiles over stable surfaces\n",
    "    ddem_ss_median, ddem_ss_nmad = np.ma.median(ddem_ss), xdem.spatialstats.nmad(ddem_ss)\n",
    "    ddem_ss_p25, ddem_ss_p75 = np.nanpercentile(ddem_ss.data.data, 25), np.nanpercentile(ddem_ss.data.data, 75)\n",
    "    \n",
    "    # Plot\n",
    "    plt.rcParams.update({'font.size': 12, 'font.sans-serif': \"Arial\"})\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,5), gridspec_kw={'width_ratios': [1,1.5]})\n",
    "    # dDEM map plot\n",
    "    ddem.plot(ax=ax[0], cmap='coolwarm_r', vmin=-5, vmax=5, cbar_title='meters')\n",
    "    ax[0].set_title('dDEM')\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    # Histograms of elevation residuals\n",
    "    bins = np.arange(-5, 5, step=0.2)\n",
    "    ax[1].hist(ddem.data.ravel(), bins=bins, \n",
    "               facecolor='gray', edgecolor='k', linewidth=0.5, label='All surfaces')\n",
    "    ax1 = ax[1].twinx()\n",
    "    hist = ax1.hist(ddem_ss.data.ravel(), bins=bins,\n",
    "                    facecolor='m', alpha=0.5, edgecolor='k', linewidth=0.5, label='Stable surfaces')\n",
    "    ax1.set_ylim(0, np.nanmax(hist[0]) * 1.5)\n",
    "    ax1.spines['right'].set_color('m')\n",
    "    ax1.tick_params(axis='y', color='m', labelcolor='m')\n",
    "    # Lines for stats\n",
    "    ax[1].axvline(ddem_ss_median, linestyle='-', color='k', linewidth=2, label=f\"Median: {np.round(float(ddem_ss_median), 2)} m\")\n",
    "    ax[1].axvline(ddem_ss_nmad, linestyle='--', color='k', linewidth=1, label=f\"NMAD: {np.round(float(ddem_ss_nmad), 2)} m\")\n",
    "    ax[1].axvline(ddem_ss_p25, linestyle='--', color='gray', linewidth=1, label=\"P$_{25}$: \" + f\"{np.round(float(ddem_ss_p25), 2)} m\")\n",
    "    ax[1].axvline(ddem_ss_p75, linestyle='--', color='gray', linewidth=1, label=\"P$_{75}$: \" + f\"{np.round(float(ddem_ss_p75), 2)} m\")\n",
    "    ax[1].set_xlabel('Elevation residual [m]')\n",
    "    ax[1].set_ylabel('Frequency')\n",
    "    ax[1].set_xlim(np.min(bins),np.max(bins))\n",
    "    # add legend\n",
    "    handles1, labels1 = ax1.get_legend_handles_labels()\n",
    "    handles2, labels2 = ax[1].get_legend_handles_labels()\n",
    "    handles = handles1 + handles2\n",
    "    labels = labels1 + labels2\n",
    "    ax[1].legend(handles, labels, loc='upper left')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure\n",
    "    fig.savefig(stats_fig_fn)\n",
    "    print('dDEM statistics plot saved to file:', stats_fig_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct snow depth map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_fn = os.path.splitext(dem_zshift_fn)[0] + '_snow_depth.tif'\n",
    "if not os.path.exists(sd_fn):\n",
    "    # Load input files\n",
    "    dem = xdem.DEM(dem_zshift_fn)\n",
    "    refdem = xdem.DEM(refdem_fn).reproject(dem)\n",
    "    snow_mask = gu.Raster(snow_mask_fn).reproject(dem)\n",
    "    snow_mask = (snow_mask == 1)\n",
    "    \n",
    "    # Calculate dDEM\n",
    "    ddem = dem - refdem\n",
    "    \n",
    "    # Mask snow-free surfaces\n",
    "    ddem.set_mask(~snow_mask)\n",
    "    \n",
    "    # Save to file\n",
    "    ddem.save(sd_fn)\n",
    "    print('Snow depth map saved to file:', sd_fn)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "    ddem.plot(cmap='Blues', vmin=0, vmax=6, ax=ax[0], cbar_title='Snow depth [m]')\n",
    "    ax[1].hist(ddem.data.ravel(), bins=np.arange(-1,6.1, step=0.2), facecolor='skyblue', edgecolor='k', linewidth=0.5)\n",
    "    ax[1].set_yticks([])\n",
    "    ax[1].set_xlabel('Snow depth [m]')\n",
    "    ax[1].set_xlim(-1,6)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print('Snow depth map already exists in file, skipping.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate resolution at which terrain parameters should be sampled by modeling the semivariogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_fn = os.path.join(data_dir, site_name, 'refdem', 'refdem_terrain_sampling_resolutions.json')\n",
    "if not os.path.exists(res_dict_fn):\n",
    "\n",
    "    def calculate_variogram_range(raster):\n",
    "        # Calculate the empirical variogram\n",
    "        print('Calculating the empirical variogram...')\n",
    "        var = xdem.spatialstats.sample_empirical_variogram(raster)\n",
    "        # Model the spherical variogram using a double-range model\n",
    "        print('Modeling the variogram...')\n",
    "        func_sum_vgm, params_vgm = xdem.spatialstats.fit_sum_model_variogram(\n",
    "            list_models=[\"Spherical\"], empirical_variogram=var\n",
    "            )\n",
    "        # Plot\n",
    "        xdem.spatialstats.plot_variogram(var, \n",
    "                                        list_fit_fun=[func_sum_vgm],\n",
    "                                        xscale_range_split=[10, 100, 1000, 10000])\n",
    "        plt.show()\n",
    "        # Estimate correlation length using the range\n",
    "        range = np.round(float(params_vgm['range'].values[0]))\n",
    "        print('Modeled range = ', range)\n",
    "        return range\n",
    "\n",
    "    def calculate_terrain_parameters(refelev, elev):\n",
    "        # Calculate terrain params\n",
    "        slope = refelev.slope()\n",
    "        aspect = refelev.aspect()\n",
    "\n",
    "        # Calculate best sampling resolution from modeled variogram range\n",
    "        res0 = refelev.res\n",
    "        refelev_res = calculate_variogram_range(refelev)\n",
    "        slope_res = calculate_variogram_range(slope)\n",
    "        aspect_res = calculate_variogram_range(aspect)\n",
    "        \n",
    "        # Resample using new res\n",
    "        elev = elev.reproject(res=(refelev_res, refelev_res))\n",
    "        slope = slope.reproject(res=(slope_res, slope_res))\n",
    "        aspect = aspect.reproject(res=(aspect_res, aspect_res))\n",
    "        \n",
    "        # Reproject back to DEM grid for later calculations\n",
    "        elev = elev.reproject(elev)\n",
    "        slope = slope.reproject(elev)\n",
    "        aspect = aspect.reproject(elev)\n",
    "        \n",
    "        # Set no-data values to NaN\n",
    "        elev.set_nodata(np.nan)\n",
    "        slope.set_nodata(np.nan)\n",
    "        aspect.set_nodata(np.nan)\n",
    "    \n",
    "        # Save results in dictionary\n",
    "        res_dict = {'original_sill_m': json.dumps(res0[0]),\n",
    "                    'elevation_sill_m': json.dumps(refelev_res),\n",
    "                    'slope_sill_m': json.dumps(slope_res),\n",
    "                    'aspect_sill_m': json.dumps(aspect_res)}\n",
    "        \n",
    "        return elev, slope, aspect, res_dict\n",
    "\n",
    "    # Load input files\n",
    "    dem = xdem.DEM(dem_zshift_fn)\n",
    "    refdem = xdem.DEM(refdem_fn).reproject(dem)\n",
    "\n",
    "    # Calculate terrain parameters\n",
    "    elev, slope, aspect, res_dict = calculate_terrain_parameters(refdem, dem)\n",
    "    with open(res_dict_fn, 'w') as f:\n",
    "        json.dump(res_dict, f)\n",
    "    print('Terrain sampling resolutions saved to file:', res_dict_fn)\n",
    "\n",
    "else:\n",
    "    print('Estimated terrain sampling already exists, loaded from file.')\n",
    "    with open(res_dict_fn, 'r') as f:\n",
    "        res_dict = json.load(f)\n",
    "\n",
    "res_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate spatial correlation in errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skysat_stereo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
